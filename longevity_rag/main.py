import os 
from crawler.arxiv_scraper import fetch_papers
from crawler.pubmed_scraper import fetch_pubmed_papers
from rag.document_store import create_vector_store
from llm.gpt_wrapper import ask_with_relevant_context
from crawler.arxiv_scraper import check_peer_validity
from utils.keyword_extractor import extract_keywords

def main():

    # Prompt the user for a question
    question = input("â“ Your question: ").strip()
    if not question:
        print("ğŸš« No question provided. Exiting.")
        return
    
    # Extract keywords to build a concise query
    keywords = extract_keywords(question)
    if keywords:
        query = " ".join(keywords)
        print(f"ğŸ”‘ Extracted keywords query: {query}")
    else:
        query = question
        print("âš ï¸ No keywords extracted, using full question as query.")

    print("ğŸ“š Fetching papers from ArXiv...")
    arxiv_papers = fetch_papers(query, max_results=3)
    print(f"ğŸ” ArXiv papers: {len(arxiv_papers)}")
    
    print("ğŸ“š Fetching papers from PubMed...")
    pubmed_papers = fetch_pubmed_papers(query, max_results=7)
    print(f"ğŸ” PubMed papers: {len(pubmed_papers)}")
    
    # Combine all papers
    papers = arxiv_papers + pubmed_papers
    print(f"ğŸ” Total fetched: {len(papers)}")
  
    valid_papers = []
    for i, paper in enumerate(papers, 1):
        source = paper.get('source', 'ArXiv')
        print(f"\nğŸ” Checking paper {i} [{source}]: {paper['title'][:80]}...")
        
        # Skip validation for PubMed papers (already peer-reviewed)
        if source == 'PubMed':
            print(f"âœ… VALID â€” Source: PubMed (peer-reviewed)")
            valid_papers.append(paper)
        else:
            validity = check_peer_validity(paper, verbose=True)
            if validity["valid"]:
                print(f"âœ… VALID â€” Venue: {validity['journal']}")
                paper.update(validity)
                valid_papers.append(paper)
            else:
                print(f"âŒ INVALID â€” Reason: {validity['reason']}")

    print(f"\nğŸ“Š Valid papers found: {len(valid_papers)}")

    if not valid_papers:
        print("ğŸš« No valid papers found. Exiting.")
        return
    

    print("ğŸ§  Creating vector store...")
    vectorstore = create_vector_store(valid_papers)

    
    print(f"\nâ“ Question: {question}")
    
    print("ğŸ¤– Calling OpenAI model...")
    answer, citations = ask_with_relevant_context(question, vectorstore)

    print(f"\nğŸ’¡ Answer: {answer}  \nâœ… and Citations: {citations}")


if __name__ == "__main__":
    main()
